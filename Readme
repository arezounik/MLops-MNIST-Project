


Experiment Name: MNIST_Classification



### How do we evaluate the performance?

for data, label in test_loader:
      data, label = data.to(device), label.to(device)
      loss, acc = test(Full_systemmodel, test_loader)
      print(f"Loss: ...",f", Accuracy: ...")
      break


### üìù Dataset Documentation

The system is trained and tested on the **MNIST** dataset.

test_loader = torch.utils.data.DataLoader(

    datasets.MNIST('./data', train=False,

                   transform=transforms.Compose([transforms.ToTensor()])), batch_size=24, shuffle=False, num_workers=4)

Each 28x28 image is vertically split into two distinct views:



view1 = data[:, :, 0:14, :] 

view2 = data[:, :, 14:, :] 



**view1: Top 14x28 pixels (used as input for Semantic_encoder1)

**view2: Bottom 14x28 pixels (used as input for Semantic_encoder2)



### üß± 8-Component System Architecture (Model Flow)

The Full_systemmodel consists of 8 interconnected PyTorch components, all logged in this Run. The processing sequence is strictly defined:


1.  **Model 1 (components_semantic_encoder1) & Model 2 (components_semantic_encoder2):** * **Function:** Feature extraction and semantic encoding of view1 and view2 (with Salt & Pepper noise).

2.  **Model 3 (components_autoencoder1) & Model 4 (components_autoencoder2):** * **Function:** Compresses and reconstructs the semantic codes while simulating channel noise (SNR).

3.  **Model 5 (components_cross_view_encoding):** * **Function:** Extracts and combines the cross-view features (e.g., z1, sub_z2, z_cat).

4.  **Model 6 (components_internal_network1) & Model 7 (components_internal_network2):**

    * **Function:** Applies projections/predictions on the extracted features for representation learning.

5.  **Model 8 (components_classifier):** * **Function:** Performs the final 10-class prediction (0-9) based on the combined features.



#Criterion:

We proposed the "negative log likelihood loss" as the criterion of test function.



....        Tout = Full_systemmodel(data)

            test_loss += (F.nll_loss(Tout, label,  reduction='sum').item())

            pred = Tout.argmax(dim=1, keepdim=True)
            correct += pred.eq(label.view_as(pred)).sum().item()


    test_loss /= len(test_loader.dataset)


    return test_loss, 100. * (correct) / len(test_loader.dataset)